# -*- coding: utf-8 -*-
"""Classical&Quantum 2.0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10JQfKq9-4C0ZkLHKdF81OembuFKu4Kz4
"""

import pandas as pd
import numpy as np

df = pd.read_csv('updated_trans.csv')

df.head(20)



df.info()

df.describe()

df.isnull()



df.isnull().sum().max()

df.columns

df_trans = df[['date', 'account_id', 'type', 'amount','trans_id','balance']]
df_trans['date'] = pd.to_datetime(df_trans['date'], format='%y%m%d')

df_trans.head(20)

df.describe()

df_trans.isnull()

df_trans.describe()

df_trans.count()

import seaborn as sns

sns.distplot(df_trans['amount'], bins=50)

sns.countplot(x='type', data=df_trans)

# Change the transaction types to English.
to_replace = {'PRIJEM': 'CREDIT', 'VYDAJ': 'WITHDRAWAL', 'VYBER': 'NOT SURE'}
df_trans['type'] = df_trans['type'].replace(to_replace)

updated_trans=df_trans.head()

updated_trans

print(updated_trans.size)



# prompt: Using dataframe updated_trans: account_id

updated_trans['account_id'].unique()

df.to_csv('updated_trans.csv', index=False)

df_withdrawals = df_trans.query('type == "WITHDRAWAL"').sort_values(by=['date','trans_id','balance']).set_index('date')

df_withdrawals.head()

df_withdrawals.info()

print (df_withdrawals.size)

df_CREDIT = df_trans.query('type == "CREDIT"').sort_values(by=['date','trans_id','balance']).set_index('date')

df_CREDIT.head()

df_withdrawals.info()

df_NOTSURE = df_trans.query('type == "NOT SURE"').sort_values(by=['date','trans_id','balance']).set_index('date')

df_NOTSURE.head()

"""# Creating Feature Constraints

# First Constraint
"""

from datetime import timedelta

# get the sum of the previous 5 days transaction amounts for withdrawals
df_withdrawals['sum_5days'] = df_withdrawals.groupby('account_id')['amount'].transform(lambda s: s.rolling(timedelta(days=5)).sum())

df_withdrawals.head(20)

"""# Second Constraint"""

df_withdrawals['count_5days'] = df_withdrawals.groupby('account_id')['amount'].transform(lambda s: s.rolling(timedelta(days=5)).count())

df_withdrawals.head(20)

# Define thresholds for sum and count to split data
sum_threshold = 1000  # Example threshold for sum of 5 days
count_threshold = 2  # Example threshold for count of 5 days

confidential_data = df_withdrawals[(df_withdrawals['sum_5days'] > sum_threshold) & (df_withdrawals['count_5days'] > count_threshold)]
public_data = df_withdrawals[(df_withdrawals['sum_5days'] <= sum_threshold) | (df_withdrawals['count_5days'] <= count_threshold)]

confidential_data.head()

confidential_data.values

public_data.head()

df_withdrawals.info()

df_CREDIT['count_5days'] = df_CREDIT.groupby('account_id')['amount'].transform(lambda s: s.rolling(timedelta(days=5)).count())

df_CREDIT.head(20)

df_CREDIT['sum_5days'] = df_CREDIT.groupby('account_id')['amount'].transform(lambda s: s.rolling(timedelta(days=5)).sum())

confidential_data_CREDIT = df_CREDIT[(df_CREDIT['sum_5days'] > sum_threshold) & (df_CREDIT['count_5days'] > count_threshold)]
public_data_CREDIT = df_CREDIT[(df_CREDIT['sum_5days'] <= sum_threshold) | (df_CREDIT['count_5days'] <= count_threshold)]

confidential_data_CREDIT.head()

public_data_CREDIT.head()

df_NOTSURE['sum_5days'] = df_NOTSURE.groupby('account_id')['amount'].transform(lambda s: s.rolling(timedelta(days=5)).sum())

df_NOTSURE['count_5days'] = df_NOTSURE.groupby('account_id')['amount'].transform(lambda s: s.rolling(timedelta(days=5)).count())

df_NOTSURE.head(20)

"""# Third Constraint"""

#Pivot table
paysim_pivot1=pd.pivot_table(df_trans,index=["type"],
                               values=['amount','balance','trans_id','account_id'],
                               aggfunc=[np.sum,np.std], margins=True)

#Adding color gradient
cm = sns.light_palette("green", as_cmap=True)
paysim_pivot1.style.background_gradient(cmap=cm)

df.info("withdrawals")

df.info("updated_trans.csv")

df.info("trans_id")

!pip install pyod

from pyod.models.iforest import IForest
from pyod.utils.data import generate_data

"""# Using pyod"""

from pyod.utils.data import evaluate_print
from pyod.utils.example import visualize

anomaly_proportion = 0.001
clf_name = 'Anomaly Detection - Isolation Forest'
clf = IForest(contamination=anomaly_proportion)

X = df_withdrawals[['count_5days', 'sum_5days']]
clf.fit(X)

# get the prediction labels and outlier scores of the training data
df_withdrawals['y_pred'] = clf.labels_ # binary labels (0: inliers, 1: outliers)
df_withdrawals['y_scores'] = clf.decision_scores_ # raw outlier scores. The bigger the number the greater the anomaly.

xx , yy = np.meshgrid(np.linspace(0, 11, 200), np.linspace(0, 180000, 200))

Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])*-1
Z = Z.reshape(xx.shape)

import matplotlib.pyplot as plt
import matplotlib.font_manager

threshold = (df_withdrawals.loc[df_withdrawals['y_pred'] == 1, 'y_scores'].min()*-1)/2 + (df_withdrawals.loc[df_withdrawals['y_pred'] == 0, 'y_scores'].max()*-1)/2


subplot = plt.subplot(1, 1, 1)

# fill blue colormap from minimum anomaly score to threshold value
subplot.contourf(xx, yy, Z, levels = np.linspace(Z.min(), threshold, 10),cmap=plt.cm.Blues_r)

# draw red contour line where anomaly score is equal to threshold
a = subplot.contour(xx, yy, Z, levels=[threshold],linewidths=2, colors='red')

# fill orange contour lines where range of anomaly score is from threshold to maximum anomaly score
subplot.contourf(xx, yy, Z, levels=[threshold, Z.max()],colors='orange')


msk = df_withdrawals['y_pred'] == 0
x = df_withdrawals.loc[msk, ['count_5days', 'sum_5days']].values

# scatter plot of inliers with white dots
b = subplot.scatter(x[:, 0], x[:, 1], c='white',s=20, edgecolor='k')


msk = df_withdrawals['y_pred'] == 1
x = df_withdrawals.loc[msk, ['count_5days', 'sum_5days']].values

# scatter plot of outliers with black dots
c = subplot.scatter(x[:, 0], x[:, 1], c='black',s=20, edgecolor='r')
subplot.axis('tight')



subplot.legend(
    [a.collections[0], b, c],
    ['learned decision function', 'inliers', 'outliers'],
    prop=matplotlib.font_manager.FontProperties(size=10),
    loc='upper right')

subplot.set_title(clf_name)
subplot.set_xlim((0, 11))
subplot.set_ylim((0, 180000))

subplot.set_xlabel("5-day count of withdrawal transactions.")
subplot.set_ylabel("5-day sum of withdrawal transactions")

"""# Quantum Computing"""

df_trans.head()

df.to_csv('df_trans.csv', index=False)

df.to_csv('df_withdrawals.csv', index=False)

df.to_csv('df_CRE.csv', index=False)

df.to_csv('df_NOTSURE_CONSTRAINTS.csv', index=False)

updated_trans.head(20)

!pip install qiskit

!pip install qiskit-machine-learning

!pip install qiskit_algorithms

!pip install pylatexenc

# Commented out IPython magic to ensure Python compatibility.
import qiskit
from qiskit.circuit.library import ZZFeatureMap
import matplotlib.pyplot as plt
# %matplotlib inline
feature_dim = 50
feature_map = ZZFeatureMap(feature_dimension=feature_dim, reps=2)
feature_map.decompose().decompose().decompose().draw(output="mpl", scale=1.0, fold=10, style="iqp")
plt.gcf().set_size_inches(16, 9)
plt.show()

from qiskit import QuantumCircuit

from qiskit.circuit.library import ZZFeatureMap

features = [0.2, 0.4, 0.8] * 17
feature_map = ZZFeatureMap(feature_dimension=len(features))

encoded = feature_map.assign_parameters(features)
encoded.draw('mpl')

from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
from qiskit.circuit.library import ZZFeatureMap
import random


# Define registers
qr = QuantumRegister(50, "q")  # 50 qubits for the feature map
cr = ClassicalRegister(50, "c")  # Classical register for measurement

# Create the circuit
circuit = QuantumCircuit(qr, cr)

# Apply the ZZFeatureMap with repetitions
zz_map = ZZFeatureMap(feature_dimension=50, reps=2)  # Create an instance
circuit.append(zz_map, qr)

# Add random sampling of gates for demonstration (replace with specific gates)
for i in range(50):  # Apply gates to all qubits (adjust loop for specific targets)
    gate_type = random.randint(1, 5)  # Choose a random gate type (replace with selection logic)
    if gate_type == 1:
        circuit.h(qr[i])  # Hadamard gate on qubit i
    elif gate_type == 2:
        control_qubit = random.randint(0, 49)  # Choose a random control qubit (adjust range)
        circuit.cx(qr[control_qubit], qr[i])  # CNOT gate with random control
    else:
        # Apply random rotation gates (Rx, Ry, Rz) with random angles
        angle = random.random() * 2 * np.pi  # Random angle between 0 and 2*pi
        if random.randint(1, 3) == 1:
            circuit.rx(angle, qr[i])
        elif random.randint(1, 3) == 2:
            circuit.ry(angle, qr[i])
        else:
            circuit.rz(angle, qr[i])

# Measure all qubits in the Z-basis
circuit.measure(qr, cr)

# Print the circuit for visualization (consider alternative methods for larger circuits)
print(circuit.draw(output="text"))  # Textual representation

# Alternatively, for smaller circuits:
# circuit.draw(output="mpl", scale=1.0)  # Plot using Matplotlib (might not scale well)
#circuite implemntation in rigouring format
#tabulation to be buil it

df = pd.read_csv('updated_trans.csv')

df.dropna(subset=['account_id'])

df.dropna(subset=['trans_id'])

df.isnull()

df.drop_duplicates()

df.isnull()

df_unique = df.drop_duplicates()

print(df_unique)

df.isnull()

# Remove null values (dropping rows with any nulls)
data_no_nulls = df.dropna()

# Show dataset without null values (using head for brevity)
print("\nDataset without null values (head):")
print(data_no_nulls.head())

# Show dataset with duplicates (using head for brevity)
print("\nDataset with duplicates (head):")
print(df.head())

# Remove duplicate rows (keeping the first occurrence)
data_no_duplicates = df.drop_duplicates()

# Show dataset without duplicates (using head for brevity)
print("\nDataset without duplicates (head):")
print(data_no_duplicates.head())

df.shape[0]

df_withdrawals.shape[0]

df_withdrawals = df_withdrawals.to_csv('df_withdrawals.csv',index=False)

import random
from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
from qiskit.circuit.library import ZZFeatureMap
import pandas as pd


def create_circuit_for_datapoint(features, num_qubits, parameter_type="fixed"):


    qr = QuantumCircuit(num_qubits, "q")
    cr = ClassicalRegister(num_qubits, "c")
    circuit = QuantumCircuit(qr, cr)

    # Pre-defined parameter values (adjust based on your algorithm and feature representation)
    if parameter_type == "fixed":
        parameter_values = [0.3, 0.1, 0.8, ...] * 50  # Example values, adjust and repeat 50 times
    elif parameter_type == "random":
        import numpy as np
        parameter_values = [random.uniform(-np.pi, np.pi) for _ in range(50)]
    else:
        raise ValueError("Invalid parameter_type. Choose 'fixed' or 'random'.")

    zz_map = ZZFeatureMap(feature_dimension=num_qubits)
    circuit.append(layer=zz_map, qargs=qr)
    circuit.assign_parameters(parameter_values, zz_map.parameters)

    # Add additional gates as needed for your specific anomaly detection algorithm

    circuit.measure(qr, cr)
    return circuit()

